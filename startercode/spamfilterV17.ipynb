{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SPAM Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Procedure\n",
    "    * Divide data in train and test sets\n",
    "    * Keep test data in a safe!\n",
    "    * Transform test data (normalize, discretize, etc)\n",
    "    * Train model\n",
    "    * Transform test data with the parameters found in step 3\n",
    "    * Test model with test data\n",
    "    * Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spambase/spambase.data\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df[df.columns[0:-1]],df[df.columns[-1]], train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "Y_train=Y_train.values\n",
    "X_test=X_test.values\n",
    "Y_test=Y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizar no ayuda mucho pero sale igual al de sklearn. Para que las alturas del pdf signifiquen lo mismo \n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Calcular las prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "P_Spam=float(sum(Y_train))/len(Y_train)\n",
    "P_noSpam=1-P_Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Separar el Spam del No Spam"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Para cada variable calcular P(X|Spam). Caracterizar la distribucion normal con la media y std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mediaS=np.mean(X_train[Y_train==1], axis=0)\n",
    "dsS=np.std(X_train[Y_train==1],axis=0)\n",
    "mediaNS=np.mean(X_train[Y_train==0],axis=0)\n",
    "dsNS=np.std(X_train[Y_train==0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#para que no haya error el default muy negativo\n",
    "def bayesClass(x):    \n",
    "    min=-len(x)*10.0\n",
    "    spam=np.log(P_Spam)+sum(np.log(norm(mediaS[i],dsS[i]).pdf(x[i]))  if norm(mediaS[i],dsS[i]).pdf(x[i]) <> 0.0  and dsS[i]>0.0  else min for i in range(len(x)))    \n",
    "    noSpam=np.log(P_noSpam)+sum(np.log(norm(mediaNS[i],dsNS[i]).pdf(x[i])) if norm(mediaNS[i],dsNS[i]).pdf(x[i]) <> 0.0  and dsNS[i]>0.0 else min  for i in range(len(x)))\n",
    "    if spam >= noSpam   :\n",
    "            return 1\n",
    "    else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#COn la integral. Asi no sirve bien. Pensar limites. No es necesario\n",
    "#def bayesClass(x):    \n",
    "#    spam=np.log(P_Spam)+sum(np.log(sp.integrate.quad(norm(mediaS[i],dsS[i]).pdf,x[i]-x[i]*0.001,x[i]+x[i]*0.001)[0])  if norm(mediaS[i],dsS[i]).pdf(x[i]) <> 0.0  and dsS[i]>0.0  else -10000.0 for i in range(len(x)))    \n",
    "#    noSpam=np.log(P_noSpam)+sum(np.log(sp.integrate.quad(norm(mediaNS[i],dsNS[i]).pdf,x[i]-x[i]*0.001,x[i]+x[i]*0.001)[0]) if norm(mediaNS[i],dsNS[i]).pdf(x[i]) <> 0.0  and dsNS[i]>0.0 else -10000.0  for i in range(len(x)))\n",
    "    \n",
    "#    if spam > noSpam   :\n",
    "#            return 1\n",
    "#    else:\n",
    "#            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res=[bayesClass(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[515, 170],\n",
       "       [ 21, 445]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "modelo=gnb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[515, 170],\n",
       "       [ 21, 445]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, modelo.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
